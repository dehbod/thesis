\chapter{مرور ادبیات}
\section{مقدمه}
عمومیت پیدا کردن داده‌های حجیم مانند داده‌های حجیم تحت وب و جریان‌های داده بزرگ در کاربردهای جدید،
موجب به وجود آمدن فرصت‌های و چالش‌هایی برای مهندسین و دانشمندان شده است.
\cite{li2007stable}
برای مثال، زمانی که ماتریس داده 
$\mathbf{A} \in \mathbb{R}^{n \times D}$
ابعادی در حد وب داشته باشد، عملیات ساده‌ای مانند محاسبه
$\mathbf{A} \mathbf{A}^T$
سخت می‌شود.
برای ارائه و نگهداری داده‌های حجیم در حافظه‌ای کوچک و برای استخراج اطلاعات آماری اصلی از مجوعه‌ای از بیانی محدود، روش‌های گوناگونی نمونه‌برداری توسعه‌ یافته است. به طور کلی روش 
\textit{تصویر تصادفی پایدار}
\LTRfootnote{Stable Random Projection}
 برای داده‌های با دم سنگین خیلی خوب کار می‌کند.

روش تصویر تصادفی پایدار، ماتریس داده‌های اولیه 
$\mathbf{A} \in \mathbb{R}^{n \times D}$
را در ماتریس تصادفی 
$\mathbf{R} \in \mathbb{R}^{D \times k}$
$(k \ll D)$
 ضرب می‌کند و نتیجه ماتریس
$\mathbf{B} = \mathbf{AR} \in \mathbb{R}^{n \times k}$
است. 
معمولا درایه‌های ماتریس تصادفی
$\mathbf{R}$
به صورت 
\lr{i.i.d}
\LTRfootnote{Independent and identically distributed random variables}
از یک توزیع 
$\alpha$
-پایدار متقارن انتخاب می‌شوند (
$ 0 < \alpha \leq 2$
).
ما می‌توانیم مشخصه‌های 
$l_\alpha$
را در 
$\mathbf{A}$
بر اساس 
$\mathbf{B}$
تخمین بزنیم. در مورد حالت 
$l_2$
مزیت توزیع تصادفی پایدار توسط لم 
\lr{JL}
\LTRfootnote{Johnson-Lindenstrauss}
برجسته شده است. لم 
\lr{JL}
بیان می‌دارد که کافی است 
$k=O(\frac{ \log  n}{\epsilon^ 2})$
باشد تا هم فاصله دو به دویی با نرم 
$l_\alpha$
در 
$\mathbf{A}$
را بتوان با ضریب 
$1 \pm \epsilon$
از روی ماتریس 
$\mathbf{B}$
تخمین زد. در تز 
\lr{Ping Li}
\cite{li2007stable}
لمی مشابه لم 
\lr{JL}
برای 
$0 < \alpha < 2$
اثبات شده است. روش تصویر تصادفی پایدار به یک مسئله تخمین آماری کاهش می‌یابد برای تخمین پارامتر مقیاس برای یک توضیع پایدار $\alpha$ متقارن. این مسئله از این جهت مورد توجه قرار می‌گیرد زیرا ما به دنبال برآوردی می‌گردیم که هم از نظر آماری درست باشند و هم از نظر محاسباتی مقرون به صرفه. برآوردگرهای مختلفی را مطالعه و مقایسه کردیم. شامل میانگین حسابی، میانگین هندسی، میانگین هارمونیک، تقسیم توانی
\LTRfootnote{fractional power}
و برآوردگر حداکثر بزرگنمایی.












\section{کاهش بعد}
\section{کاهش بعد}
\section{کاهش بعد}

\section{کاهش بعد}
\subsection{بارگیری مراجع}

